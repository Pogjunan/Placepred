{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39624659-91ca-4edc-9802-eb2d47a8aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba5aae26-8985-4c9d-8d10-21536722e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cae99edd-c102-4c68-9d7c-330bdc3fd870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "634b81c6-d274-4391-b6cb-afde7135b4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.PNG</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.PNG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.PNG</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>006.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>007.PNG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>008.PNG</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>009.PNG</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>010.PNG</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  label\n",
       "0   001.PNG      9\n",
       "1   002.PNG      4\n",
       "2   003.PNG      1\n",
       "3   004.PNG      1\n",
       "4   005.PNG      6\n",
       "5   006.PNG      1\n",
       "6   007.PNG      5\n",
       "7   008.PNG      8\n",
       "8   009.PNG      7\n",
       "9   010.PNG      7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./\"\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b77514d8-7f8d-470d-ab13-f474482c3fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'087.PNG'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05916d57-1128-4355-a05a-c12ce67ed2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'001.PNG'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_folder = file_path  + 'train'\n",
    "img_set  = os.listdir(img_folder)\n",
    "print(img_folder)\n",
    "img_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c35e1d66-74d7-42fa-8e9d-0abfe477b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "for i in range(len(os.listdir(img_folder))):\n",
    "    img_list.append(img_folder +'/' + os.listdir((os.path.join(img_folder)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2390924-f8f2-4b76-aac7-673289f526d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for i in range(len(os.listdir(data_dir))):\n",
    "        img_path_list.append(data_dir +'/' + os.listdir((os.path.join(data_dir)))[i])\n",
    "        img_path_list.sort(key = lambda x : int(x.split('/')[-1].split('.')[0]))\n",
    "    \n",
    "    label_list.extend(train_df['label'])\n",
    "    \n",
    "    return img_path_list,label_list\n",
    "\n",
    "def get_test_data(data_dir):\n",
    "    img_path_list = []\n",
    "    for i in range(len(os.listdir(data_dir))):\n",
    "        img_path_list.append(data_dir +'/' + os.listdir((os.path.join(data_dir)))[i])\n",
    "        img_path_list.sort(key = lambda x : int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "    return img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e14856c4-7a51-4dd8-aa06-d10d9838d0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_folder\n",
    "img_folder2 = file_path +'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53092858-11fd-434f-9857-ca5f96935890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_img_path, all_label = get_train_data(img_folder)\n",
    "test_img_path = get_test_data(img_folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e56ec2d2-0fc2-446c-95b2-edaec26eea74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05c8a0d5-4108-4fd2-91e4-c7b9c7b47af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e619d09-7702-4f69-94a3-9ca869cea4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode = True, transforms = None):\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_path_list[idx]\n",
    "        image = cv.imread(img_path)\n",
    "\n",
    "            \n",
    "        if self.train_mode and transforms is not None:\n",
    "            label = self.label_list[idx]\n",
    "            augmentation = rand.randint(0,8)\n",
    "            if augmentation < 3:\n",
    "                pass\n",
    "            \n",
    "            elif augmentation == 3:\n",
    "                image = cv.rotate(image, cv.ROTATE_90_CLOCKWISE)\n",
    "            \n",
    "            elif augmentation == 4:\n",
    "                image = cv.rotate(image, cv.ROTATE_90_CLOCKWISE)\n",
    "            \n",
    "            elif augmentation == 5:\n",
    "                image = image[::-1].copy()\n",
    "                \n",
    "            elif augmentation == 6:\n",
    "                image = image[:,::-1].copy()\n",
    "            \n",
    "            elif augmentation == 7:\n",
    "                image = image[::-1,::-1,:].copy()\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "\n",
    "            return image, label\n",
    "        else:\n",
    "            return self.transforms(image)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34968594-f659-4efc-b261-06ceaaea4e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_len = int(len(all_img_path) * 0.8)\n",
    "val_len = int(len(all_img_path) * 0.8)\n",
    "\n",
    "train_img_path = all_img_path[:train_len]\n",
    "train_label  = all_label[:train_len]\n",
    "\n",
    "val_img_path = all_img_path[train_len:]\n",
    "val_label = all_label[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a20b58d6-7cdf-490d-b582-cd7c249a2b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "578\n"
     ]
    }
   ],
   "source": [
    "print(len(val_label))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "463cf863-9b9b-4d75-8771-8b0497e983d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([\n",
    "        transforms.ToPILImage(), #numpy에서 pil이미지로\n",
    "        transforms.Resize([128, 128]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([128, 128]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19752fb6-3ee0-49c3-ba7c-5f5007680deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindataset = Custom_dataset(train_img_path, train_label, True, train_trans)\n",
    "train_loader = DataLoader(traindataset, batch_size = 16, shuffle = True)\n",
    "\n",
    "valdataset = Custom_dataset(val_img_path, val_label, True, test_trans)\n",
    "val_loader = DataLoader(valdataset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4166e92b-574f-4609-8c4a-a2bb5ef4b16c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "972aea83-986f-4ee1-99a5-c4b6ec287603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Custom_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_model, self).__init__()\n",
    "        self.model = timm.create_model('vgg16', pretrained = True, num_classes = 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9243625-6dfb-4ea7-951e-dda7a474216b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Custom_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4794fd65-3b21-451e-90d0-327aff284fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
      "              ReLU-2         [-1, 64, 128, 128]               0\n",
      "            Conv2d-3         [-1, 64, 128, 128]          36,928\n",
      "              ReLU-4         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-5           [-1, 64, 64, 64]               0\n",
      "            Conv2d-6          [-1, 128, 64, 64]          73,856\n",
      "              ReLU-7          [-1, 128, 64, 64]               0\n",
      "            Conv2d-8          [-1, 128, 64, 64]         147,584\n",
      "              ReLU-9          [-1, 128, 64, 64]               0\n",
      "        MaxPool2d-10          [-1, 128, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]         295,168\n",
      "             ReLU-12          [-1, 256, 32, 32]               0\n",
      "           Conv2d-13          [-1, 256, 32, 32]         590,080\n",
      "             ReLU-14          [-1, 256, 32, 32]               0\n",
      "           Conv2d-15          [-1, 256, 32, 32]         590,080\n",
      "             ReLU-16          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-17          [-1, 256, 16, 16]               0\n",
      "           Conv2d-18          [-1, 512, 16, 16]       1,180,160\n",
      "             ReLU-19          [-1, 512, 16, 16]               0\n",
      "           Conv2d-20          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-21          [-1, 512, 16, 16]               0\n",
      "           Conv2d-22          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-23          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-24            [-1, 512, 8, 8]               0\n",
      "           Conv2d-25            [-1, 512, 8, 8]       2,359,808\n",
      "             ReLU-26            [-1, 512, 8, 8]               0\n",
      "           Conv2d-27            [-1, 512, 8, 8]       2,359,808\n",
      "             ReLU-28            [-1, 512, 8, 8]               0\n",
      "           Conv2d-29            [-1, 512, 8, 8]       2,359,808\n",
      "             ReLU-30            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-31            [-1, 512, 4, 4]               0\n",
      "           Conv2d-32           [-1, 4096, 1, 1]     102,764,544\n",
      "             ReLU-33           [-1, 4096, 1, 1]               0\n",
      "          Dropout-34           [-1, 4096, 1, 1]               0\n",
      "           Conv2d-35           [-1, 4096, 1, 1]      16,781,312\n",
      "             ReLU-36           [-1, 4096, 1, 1]               0\n",
      "          ConvMlp-37           [-1, 4096, 1, 1]               0\n",
      "AdaptiveAvgPool2d-38           [-1, 4096, 1, 1]               0\n",
      "          Flatten-39                 [-1, 4096]               0\n",
      "SelectAdaptivePool2d-40                 [-1, 4096]               0\n",
      "          Dropout-41                 [-1, 4096]               0\n",
      "           Linear-42                   [-1, 10]          40,970\n",
      "         Identity-43                   [-1, 10]               0\n",
      "   ClassifierHead-44                   [-1, 10]               0\n",
      "              VGG-45                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 134,301,514\n",
      "Trainable params: 134,301,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 71.63\n",
      "Params size (MB): 512.32\n",
      "Estimated Total Size (MB): 584.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size = (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b72661d-a443-45d9-a041-a88121dfb66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52386b83-96d9-47de-b1d0-7e1355f1748c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, val_loader, optimizer):\n",
    "    n = len(dataloader)\n",
    "    \n",
    "    for epoch in range(1, 10):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        \n",
    "        for img, label in tqdm(iter(dataloader)):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        print('Epoch : ', epoch, 'Loss : ', running_loss / len(dataloader))\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in tqdm(iter(val_loader)):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                pred = model(img)\n",
    "                val_loss += criterion(pred, label)\n",
    "                pred = pred.argmax(dim = 1, keepdim = True)\n",
    "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "        val_acc = 100 * correct / len(val_loader)\n",
    "        print('Val loss : ', val_loss / len(val_loader), 'Accuracy : ', val_acc , 'correct : ', correct)\n",
    "        torch.save(model.state_dict(), 'best_model.pth')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f0c9e45-c2a6-471a-8f6d-d8eb2fee6dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 Loss :  2.7200521069603996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.3254, device='cuda:0') Accuracy :  120.0 correct :  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  2 Loss :  2.3215243494188464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.3052, device='cuda:0') Accuracy :  120.0 correct :  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  3 Loss :  2.2534547528705082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(3.7013, device='cuda:0') Accuracy :  130.0 correct :  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  4 Loss :  2.439782000876762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.3112, device='cuda:0') Accuracy :  230.0 correct :  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  5 Loss :  2.2169705178286576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.0922, device='cuda:0') Accuracy :  380.0 correct :  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  6 Loss :  2.2169615352475964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.4063, device='cuda:0') Accuracy :  250.0 correct :  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  7 Loss :  2.249227398150676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2935, device='cuda:0') Accuracy :  130.0 correct :  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  8 Loss :  2.034423451165895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.0417, device='cuda:0') Accuracy :  380.0 correct :  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  9 Loss :  1.8999107302846134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2696, device='cuda:0') Accuracy :  310.0 correct :  31\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68c307f6-2185-49ca-8585-8fc9596ead40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 Loss :  1.9859446480467513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2958, device='cuda:0') Accuracy :  340.0 correct :  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  2 Loss :  1.9773171753496737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(1.9707, device='cuda:0') Accuracy :  390.0 correct :  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  3 Loss :  1.9581925675675675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.1302, device='cuda:0') Accuracy :  300.0 correct :  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  4 Loss :  1.9633793669777948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.1843, device='cuda:0') Accuracy :  300.0 correct :  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  5 Loss :  1.9583353480777226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2501, device='cuda:0') Accuracy :  310.0 correct :  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  6 Loss :  1.9544097958384334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.1317, device='cuda:0') Accuracy :  270.0 correct :  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  7 Loss :  2.0022925009598604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2679, device='cuda:0') Accuracy :  280.0 correct :  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  8 Loss :  1.991623056901468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2191, device='cuda:0') Accuracy :  320.0 correct :  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  9 Loss :  1.977701728408401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss :  tensor(2.2162, device='cuda:0') Accuracy :  280.0 correct :  28\n"
     ]
    }
   ],
   "source": [
    "check_point = 'best_model.pth'\n",
    "\n",
    "check_point = torch.load(check_point)\n",
    "model = Custom_model().to(device)\n",
    "model.load_state_dict(check_point)\n",
    "train(model, train_loader, val_loader, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95b74693-b322-4430-a0fc-6c650396e884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "  model.eval()\n",
    "  pred_list = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for img in tqdm(iter(test_loader)):\n",
    "      img = img.to(device)\n",
    "\n",
    "      pred = model(img)\n",
    "      pred = pred.argmax(dim = 1, keepdim = True).squeeze(1)\n",
    "\n",
    "      pred_list.extend(pred.tolist())\n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0de5189c-2533-4c76-83f9-628f64a27531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  8.12it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Custom_dataset(test_img_path, None, train_mode = False, transforms = test_trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 8, shuffle = False)\n",
    "\n",
    "check_point = 'best_model.pth'\n",
    "\n",
    "check_point = torch.load(check_point)\n",
    "model = Custom_model().to(device)\n",
    "model.load_state_dict(check_point)\n",
    "\n",
    "preds = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "887f80eb-abb7-4cca-b51f-9606e3e838d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 9, 7, 2, 4, 3, 5, 3, 2]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc59be0e-9b95-4b01-8432-586157895f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e9c90f3-d5e3-46ca-861e-4cc82b714e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('first_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80346d8d-318d-45a3-a587-3e79827ea5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
